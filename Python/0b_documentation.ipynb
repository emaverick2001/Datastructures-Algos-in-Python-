{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81b3ed5b",
   "metadata": {},
   "source": [
    "# Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34375613",
   "metadata": {},
   "source": [
    "## README Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daffdcd",
   "metadata": {},
   "source": [
    "- Project title and description\n",
    "- Installation instructions\n",
    "- Usage examples\n",
    "- API documentation (or link)\n",
    "- Contributing guidelines\n",
    "- License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open-Source Research Project in Python: A Template\n",
    "\n",
    "[![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)](https://www.python.org/downloads/release/python-3109/)\n",
    "[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://pre-commit.com/)\n",
    "`<a href=\"https://github.com/psf/black\"><img alt=\"Code style: black\" src=\"https://img.shields.io/badge/code%20style-black-000000.svg\">``</a>`\n",
    "[![Checked with mypy](https://www.mypy-lang.org/static/mypy_badge.svg)](https://mypy-lang.org/)\n",
    "[![bear-ified](https://raw.githubusercontent.com/beartype/beartype-assets/main/badge/bear-ified.svg)](https://beartype.readthedocs.io)\n",
    "[![Github Action](https://github.com/lwaekfjlk/python-project-template/actions/workflows/pytest.yml/badge.svg?branch=main)]()\n",
    "\n",
    "> [!NOTE]\n",
    "> This repo is continuously updating with more tools. Any contribution is welcome.\n",
    "\n",
    "## âœ¨ Description\n",
    "\n",
    "## Features\n",
    "\n",
    "## Documentation\n",
    "\n",
    "## Installation\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "## ðŸ”¨ Continuous Integration (CI) Workflow\n",
    "\n",
    "Here's a clearer and more straightforward guideline of the steps for working with your codebase. If working in a small group or working on a simple project, some of the steps can be skipped.\n",
    "\n",
    "1. **Create Issue**\n",
    "\n",
    "   Before starting, open a new issue in the repository detailing what you plan to implement. Assign the issue to yourself.\n",
    "2. **Sync Repo**\n",
    "\n",
    "   Update your local repository to match the latest version of the remote repository.\n",
    "3. **Create Branch**\n",
    "\n",
    "   Create a new branch for your task. Name it appropriately based on the type of task, such as `feature/feature-name`, `bug/bug-name`, or `exp/exp-name`.\n",
    "4. **Implement Code**\n",
    "\n",
    "   Work on your task and make necessary changes to the codebase.\n",
    "5. **Test Locally**\n",
    "\n",
    "   Run tests using tools like mypy, pytest, and pre-commit. Ensure all tests pass before proceeding.\n",
    "6. **Change Commit**\n",
    "\n",
    "   Add and commit your changes to the branch, then push the branch to the repository.\n",
    "7. **Create PR**\n",
    "\n",
    "   Open a Pull Request (PR) for the branch you've pushed.\n",
    "8. **Link PR to Issue**\n",
    "\n",
    "   In your PR, include \"Closes #ISSUE_NUM\" to link it to the original issue.\n",
    "9. **Pass Continuous Integration**\n",
    "\n",
    "   Ensure all GitHub Actions checks pass. If they fail, revise your code based on the errors reported.\n",
    "10. **Review PR Checklist**\n",
    "\n",
    "    Verify that all items in the PR checklist are completed, such as updating documentation or adding package requirements.\n",
    "11. **Ask for Code Review**\n",
    "\n",
    "    Invite a colleague to review your PR. One approved, Use the \"Squash and Merge\" option to merge your PR, ensuring a clean commit history.\n",
    "12. **Troubleshooting**\n",
    "\n",
    "    If you break down the commit history or main branch, contact the repository owner for assistance with `rebase` or other needed actions.\n",
    "\n",
    "## ðŸ’¼ Template Structure\n",
    "\n",
    "The current project template supports the final package release of our codebase.\n",
    "\n",
    "```\n",
    "Template/\n",
    "â”‚\n",
    "â”œâ”€â”€ .github/                  # Contains GitHub related files like workflows\n",
    "â”œâ”€â”€ docs/                     # Documentation for the project\n",
    "â”œâ”€â”€ src/                      # Main package directory\n",
    "â”œâ”€â”€ stubs/                    # Type stubs for static typing (for mypy strict mode)\n",
    "â”œâ”€â”€ tests/                    # Test scripts and resources\n",
    "â”‚\n",
    "â”œâ”€â”€ .gitignore                # Specifies untracked files to ignore\n",
    "â”œâ”€â”€ .pre-commit-config.yaml   # Configurations for pre-commit hooks\n",
    "â”œâ”€â”€ poetry.lock               # Lock file generated by poetry for dependencies\n",
    "â”œâ”€â”€ pyproject.toml            # Project metadata and tool configurations\n",
    "```\n",
    "\n",
    "## â“ Issue & Pull Request\n",
    "\n",
    "An issue typically describes a new feature (`feature`), fixing an old bug (`bug`), launching a group of experiments (`exp`), or refactoring part of the code (`refactor`). Using different issue templates for different issues.\n",
    "\n",
    "A PR typically implements the content mentioned in one issue.\n",
    "\n",
    "Notice about the development:\n",
    "\n",
    "1. When creating an issue, assign the responsible member for fixing that if possible\n",
    "2. When creating a PR, make sure you uses `feature/feature-name`, `bug/bug-name`, `exp/exp-name` for its branch\n",
    "3. When finishing one PR, make sure all the github action is passed and all the checks are done.\n",
    "4. When merging one PR, make sure using `squash and merge` instead of `merge a pull request`.\n",
    "5. Avoid making any direct commit to the `main` branch and try to avoid any `--force` push to any branch unless you are pretty sure about that.\n",
    "\n",
    "## ðŸ‘· Type Checking\n",
    "\n",
    "- Tools\n",
    "\n",
    "  - static type checking (`mypy`)\n",
    "  - dynamic type checking (`beartype`)\n",
    "- Guidelines\n",
    "\n",
    "  - Run `mypy --strict ./` under the root of the current repo to test the static type.\n",
    "\n",
    "## ðŸ…ï¸ Unit Testing\n",
    "\n",
    "- Tools\n",
    "\n",
    "  - testing code components based on testing function (`pytest`)\n",
    "- Guidelines\n",
    "\n",
    "  - Run `pytest` under the root of the current repo to check unit test results.\n",
    "\n",
    "## ðŸ§ Code Spell Checking\n",
    "\n",
    "- Tools\n",
    "\n",
    "  - code spell checking (`codespell`)\n",
    "- Guidelines\n",
    "\n",
    "  - Commonly need to ignore part of the files in the repository like `/data`.\n",
    "\n",
    "## ðŸª Pre-commit Hook\n",
    "\n",
    "- Tools\n",
    "\n",
    "  - code formatting (`prettier`)\n",
    "  - import package sorting (`isort`)\n",
    "  - ipynb output clear (`nbstripout`)\n",
    "  - code bug checking (`ruff`)\n",
    "- Guidelines\n",
    "\n",
    "  - Run `python -m pip install pre-commit` to install `pre-commit`\n",
    "  - Run `pre-commit install` to allow hooking pre-commit with any `git commit` commands.\n",
    "\n",
    "## ðŸ§‘â€ðŸ’¼ Dependency Management\n",
    "\n",
    "- Tools\n",
    "\n",
    "  - We utilize `poetry` to support the dependency requirements. Dependency for different usage of the repo can be defined separately in `pyproject.toml`.\n",
    "- Guidelines\n",
    "\n",
    "  - Run `pip install poetry` to finish the installation of poetry.\n",
    "  - Create `conda environment` with a specified Python version\n",
    "  - Run `poetry install` to install required dependencies.\n",
    "\n",
    "## â¤ï¸ Contribution\n",
    "\n",
    "I welcome all kinds of contributions, e.g. adding more tools, better practices, and discussion on trade-offs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f865d78",
   "metadata": {},
   "source": [
    "## Module Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a70b81",
   "metadata": {},
   "source": [
    "- Module docstring at the very top of the file (before imports)\n",
    "- Describes module purpose, contents, and usage examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data utilities for processing CSV and JSON files.\n",
    "\n",
    "This module provides helper functions for loading, validating,\n",
    "and transforming data from various file formats.\n",
    "\n",
    "Functions:\n",
    "    load_csv: Load data from a CSV file.\n",
    "    load_json: Load data from a JSON file.\n",
    "    validate: Validate data against a schema.\n",
    "    transform: Apply transformations to data.\n",
    "\n",
    "Classes:\n",
    "    DataLoader: Async data loader with caching.\n",
    "    Schema: Data validation schema.\n",
    "\n",
    "Example:\n",
    "    >>> from data_utils import load_csv, validate\n",
    "    >>> data = load_csv('users.csv')\n",
    "    >>> validate(data, schema='user')\n",
    "\n",
    "Note:\n",
    "    Requires pandas >= 2.0 for full functionality.\n",
    "\n",
    "Todo:\n",
    "    * Add support for Parquet files\n",
    "    * Implement streaming for large files\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "# ... rest of module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e7ebde",
   "metadata": {},
   "source": [
    "## Class Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2473276",
   "metadata": {},
   "source": [
    "- Class docstring: describes the class purpose and attributes\n",
    "- Method docstrings: describe individual methods\n",
    "- \\__init__ can have its own docstring or be documented in class docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a68ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    \"\"\"\n",
    "    A class for processing and transforming data.\n",
    "\n",
    "    This class provides methods for loading, cleaning, and\n",
    "    transforming datasets for analysis.\n",
    "\n",
    "    Attributes:\n",
    "        data: The loaded dataset as a list of dicts.\n",
    "        is_cleaned: Whether the data has been cleaned.\n",
    "        source: Original data source path.\n",
    "\n",
    "    Examples:\n",
    "        >>> processor = DataProcessor('data.csv')\n",
    "        >>> processor.clean()\n",
    "        >>> processor.transform()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, source):\n",
    "        \"\"\"\n",
    "        Initialize the DataProcessor.\n",
    "\n",
    "        Args:\n",
    "            source: Path to the data source file.\n",
    "        \"\"\"\n",
    "        self.source = source\n",
    "        self.data = None\n",
    "        self.is_cleaned = False\n",
    "\n",
    "    def clean(self, remove_nulls=True):\n",
    "        \"\"\"\n",
    "        Clean the loaded data.\n",
    "\n",
    "        Args:\n",
    "            remove_nulls: Whether to remove null values. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            Self for method chaining.\n",
    "        \"\"\"\n",
    "        self.is_cleaned = True\n",
    "        return self\n",
    "\n",
    "print(DataProcessor.__doc__)\n",
    "print(DataProcessor.clean.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea0e0a",
   "metadata": {},
   "source": [
    "## Function Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e20168",
   "metadata": {},
   "source": [
    "- Triple-quoted strings immediately after function/class/module definition\n",
    "- Accessible via __doc__ attribute or help()\n",
    "- First line should be a brief summary ending with a period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56896cd",
   "metadata": {},
   "source": [
    "### Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e079ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return a greeting message for the given name.\n",
      "Help on function greet in module __main__:\n",
      "\n",
      "greet(name)\n",
      "    Return a greeting message for the given name.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def greet(name):\n",
    "    \"\"\"Return a greeting message for the given name.\"\"\"\n",
    "    return f\"Hello, {name}!\"\n",
    "\n",
    "print(greet.__doc__)\n",
    "help(greet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9533817",
   "metadata": {},
   "source": [
    "### Multi-line Docstrings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee411dbf",
   "metadata": {},
   "source": [
    "- First line: brief summary\n",
    "- Blank line\n",
    "- Extended description, parameters, return values, examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9745583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_area(length, width):\n",
    "    \"\"\"\n",
    "    Calculate the area of a rectangle by multiplying length by width to compute\n",
    "    the area of a rectangle.\n",
    "\n",
    "    Args:\n",
    "        length: The length of the rectangle.\n",
    "        width: The width of the rectangle.\n",
    "\n",
    "    Returns:\n",
    "        The area as a float.\n",
    "    \"\"\"\n",
    "    return length * width\n",
    "\n",
    "print(calculate_area.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b83e7",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f465680",
   "metadata": {},
   "source": [
    "- Explain why, not what (code should be self-explanatory)\n",
    "- Document non-obvious algorithms or business logic\n",
    "- Mark TODOs, FIXMEs, and temporary workarounds\n",
    "- Avoid redundant comments that repeat the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c060ff",
   "metadata": {},
   "source": [
    "### Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3b63ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good comments - explain WHY\n",
    "\n",
    "# Use binary search since data is sorted and large (>1M records)\n",
    "def find_user(users, user_id):\n",
    "    left, right = 0, len(users) - 1\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "        if users[mid]['id'] == user_id:\n",
    "            return users[mid]\n",
    "        elif users[mid]['id'] < user_id:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "    return None\n",
    "\n",
    "# API returns dates in non-standard format, convert to ISO\n",
    "def normalize_date(date_str):\n",
    "    # Format: DD/MM/YYYY HH:MM -> YYYY-MM-DD\n",
    "    parts = date_str.split()[0].split('/')\n",
    "    return f\"{parts[2]}-{parts[1]}-{parts[0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bad Comments - Avoid These\n",
    "\n",
    "# Increment counter by 1\n",
    "counter = counter + 1  # BAD: obvious\n",
    "\n",
    "# Loop through users\n",
    "for user in users:  # BAD: obvious\n",
    "    pass\n",
    "\n",
    "# Check if x is greater than 10\n",
    "if x > 10:  # BAD: obvious\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69250bc",
   "metadata": {},
   "source": [
    "### Special Comment Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9a1698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add pagination support\n",
    "def get_all_users():\n",
    "    pass\n",
    "\n",
    "# FIXME: This breaks with unicode characters\n",
    "def parse_name(name):\n",
    "    pass\n",
    "\n",
    "# HACK: Workaround for API bug, remove after v2.0 release\n",
    "def fetch_data():\n",
    "    pass\n",
    "\n",
    "# NOTE: This function is called in a hot loop, keep it fast\n",
    "def calculate_hash(data):\n",
    "    pass\n",
    "\n",
    "# XXX: Deprecated, use new_function() instead\n",
    "def old_function():\n",
    "    pass\n",
    "\n",
    "# PERF: O(nÂ²) - consider optimization for large inputs\n",
    "def find_duplicates(items):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c69929b",
   "metadata": {},
   "source": [
    "### Inline Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c772b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inline comments - use sparingly, 2 spaces before #\n",
    "\n",
    "x = x + 1  # Compensate for border offset\n",
    "\n",
    "config = {\n",
    "    'timeout': 30,      # seconds\n",
    "    'retries': 3,       # attempts before failure\n",
    "    'backoff': 2.0,     # exponential backoff multiplier\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69477ccb",
   "metadata": {},
   "source": [
    "## Type Hints in Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba77c5d",
   "metadata": {},
   "source": [
    "- Type hints provide inline type documentation\n",
    "- Combine with docstrings for complete documentation\n",
    "- Tools like mypy verify type correctness\n",
    "- NOTE refer to 5_modules_libraries_packages.ipynb for more about the typing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3aee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Dict, Union\n",
    "\n",
    "def search_users(\n",
    "    query: str,\n",
    "    limit: int = 10,\n",
    "    filters: Optional[Dict[str, str]] = None\n",
    ") -> List[Dict[str, Union[str, int]]]:\n",
    "    \"\"\"\n",
    "    Search for users matching the query.\n",
    "\n",
    "    Args:\n",
    "        query: Search query string.\n",
    "        limit: Maximum number of results.\n",
    "        filters: Optional filters to apply.\n",
    "\n",
    "    Returns:\n",
    "        List of user dicts with 'id', 'name', 'email' keys.\n",
    "    \"\"\"\n",
    "    return []\n",
    "\n",
    "print(search_users.__annotations__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8efeeac",
   "metadata": {},
   "source": [
    "# Standards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0513d2f",
   "metadata": {},
   "source": [
    "## PEP8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d60ea3",
   "metadata": {},
   "source": [
    "- Use **snake_case** for variables and functions (`max_value`, `calculate_mean`)\n",
    "- Use **PascalCase** for class names (`DataProcessor`, `LinearModel`)\n",
    "- Keep line length â‰¤ 79 characters\n",
    "- Use 4 spaces per indentation level (no tabs)\n",
    "- Use **two blank lines** between top-level functions and classes\n",
    "- Use **one blank line** between class methods\n",
    "- Imports at the top in order:\n",
    "  1. Standard library\n",
    "  2. Third-party libraries\n",
    "  3. Local imports\n",
    "  - Example:\n",
    "    ```python\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from utils.data_loader import load_csv\n",
    "    ```\n",
    "- Keep imports grouped with blank lines between groups\n",
    "- Avoid wildcard imports (`from x import *`)\n",
    "- Prefer explicit relative imports inside packages\n",
    "- Use f-strings; avoid string concatenation in loops\n",
    "- Document tricky parts with short comments (why > what)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88082f4",
   "metadata": {},
   "source": [
    "## Google Docstring Style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cf6d00",
   "metadata": {},
   "source": [
    "- Most readable and widely used\n",
    "- Sections: Args, Returns, Raises, Examples, Attributes, Note, Todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e1e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(url, timeout=30, retries=3):\n",
    "    \"\"\"\n",
    "    Fetch data from a URL with retry logic.\n",
    "\n",
    "    Makes an HTTP GET request to the specified URL and returns\n",
    "    the response data. Automatically retries on failure.\n",
    "\n",
    "    Args:\n",
    "        url: The URL to fetch data from.\n",
    "        timeout: Request timeout in seconds. Defaults to 30.\n",
    "        retries: Number of retry attempts. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        A dict containing the response data with keys:\n",
    "            - 'status': HTTP status code\n",
    "            - 'data': Response body as string\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If URL is empty or malformed.\n",
    "        TimeoutError: If all retry attempts fail.\n",
    "\n",
    "    Examples:\n",
    "        >>> fetch_data('https://api.example.com/data')\n",
    "        {'status': 200, 'data': '...'}\n",
    "\n",
    "        >>> fetch_data('https://api.example.com/data', timeout=10)\n",
    "        {'status': 200, 'data': '...'}\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a15097",
   "metadata": {},
   "source": [
    "## NumPy Style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11facf50",
   "metadata": {},
   "source": [
    "- Common in scientific Python (NumPy, SciPy, pandas)\n",
    "- More verbose with underlined sections\n",
    "- Good for complex parameter descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e84a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(data, weights=None):\n",
    "    \"\"\"\n",
    "    Compute weighted statistics for a dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array_like\n",
    "        Input data array of shape (n_samples,).\n",
    "    weights : array_like, optional\n",
    "        Weights for each sample. If None, uniform weights\n",
    "        are used. Must have same shape as data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing:\n",
    "        - mean : float\n",
    "            Weighted mean of the data.\n",
    "        - std : float\n",
    "            Weighted standard deviation.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If data and weights have different shapes.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    numpy.average : Compute weighted average.\n",
    "    numpy.std : Compute standard deviation.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> compute_statistics([1, 2, 3, 4, 5])\n",
    "    {'mean': 3.0, 'std': 1.414...}\n",
    "\n",
    "    >>> compute_statistics([1, 2, 3], weights=[0.5, 0.3, 0.2])\n",
    "    {'mean': 1.7, 'std': ...}\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e8d72b",
   "metadata": {},
   "source": [
    "# Projects for Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432c60e",
   "metadata": {},
   "source": [
    "- Document an existing project with proper docstrings\n",
    "- Set up Sphinx/MkDocs for a project\n",
    "- Add doctest examples to a utility module\n",
    "- Write a comprehensive README for a project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
